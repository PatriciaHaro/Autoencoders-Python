{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class myVoxel():\n",
    "    def __init__(self, nx, ny, nz, shortptc, shortptc_legend, alpha_Def1=['number_of_points'], alpha_Def2=['sum','avg'],\n",
    "                    define_alpha1_as_alpha2type=False):\n",
    "        self.alpha1 = alpha_Def1\n",
    "        self.alpha2 = alpha_Def2\n",
    "        self.nx = nx  \n",
    "        self.ny = ny\n",
    "        self.nz = nz\n",
    "        self.define_alpha1_as_alpha2type = define_alpha1_as_alpha2type\n",
    "        self.shortptc = shortptc\n",
    "        self.shortptc_legend = shortptc_legend\n",
    "        self.Nsamples = self.shortptc.shape[0] \n",
    "        self.Nalphas = self.shortptc.shape[1] - 3 \n",
    "        \n",
    "        self.all_mins, self.all_maxs = self.create_bb() \n",
    "        print('mins and maxs', self.all_mins, self.all_maxs)\n",
    "        \n",
    "        self.voxel_size_x, self.voxel_size_y, self.voxel_size_z = self.voxel_sizes() \n",
    "        print('voxel sizes', self.voxel_size_x, self.voxel_size_y, self.voxel_size_z)\n",
    "        \n",
    "        self.voxel_dict = self.create_voxel()\n",
    "        #print('voxel_dict', self.voxel_dict)\n",
    "        \n",
    "        self.voxel_matrix = self.create_voxel_matrix() \n",
    "        print('voxel_matrix', self.voxel_matrix.shape)\n",
    "        #print('voxel_matrix', self.voxel_matrix)\n",
    "        \n",
    "        del self.shortptc\n",
    "        del self.voxel_dict\n",
    "    \n",
    "    def create_bb(self,): \n",
    "        all_mins = [np.min(self.shortptc[k]) for k in ['x','y','z']] \n",
    "        all_maxs = [np.max(self.shortptc[k]) for k in ['x','y','z']]  \n",
    "        return all_mins, all_maxs\n",
    "    \n",
    "    def voxel_sizes(self,):\n",
    "        scales = [self.all_maxs[k] - self.all_mins[k] for k in range(3)]\n",
    "        for k in range(3): \n",
    "            voxel_size_x = scales[0] / self.nx \n",
    "            voxel_size_y = scales[1] / self.ny\n",
    "            voxel_size_z = scales[2] / self.nz\n",
    "        return voxel_size_x, voxel_size_y, voxel_size_z\n",
    "        \n",
    "    def create_voxel(self,):\n",
    "        voxel_dict = {} \n",
    "        \n",
    "        for ix in range(self.nx): \n",
    "            voxel_dict[ix] = {}            \n",
    "            for iy in range(self.ny):\n",
    "                voxel_dict[ix][iy] = {}                \n",
    "                for iz in range(self.nz):\n",
    "                    voxel_dict[ix][iy][iz] = {'list_of_nodes': [],  \n",
    "                                              'prop1':[],\n",
    "                                              'prop2':[]}\n",
    "                    \n",
    "        for pt in range(self.shortptc.shape[0]): \n",
    "            var = (self.shortptc['x'][pt] - self.all_mins[0]) /self.voxel_size_x # Why all_mins[0]? first column?\n",
    "            #print(var)\n",
    "            voxel_ix = int(np.floor(var)) \n",
    "            #print(voxel_ix)\n",
    "            \n",
    "            var = (self.shortptc['y'][pt] - self.all_mins[1]) / self.voxel_size_y \n",
    "            #print(var)\n",
    "            voxel_iy = int(np.floor(var))\n",
    "            #print(voxel_iy)\n",
    "            \n",
    "            var = (self.shortptc['z'][pt] - self.all_mins[2]) / self.voxel_size_z\n",
    "            #print(var)\n",
    "            voxel_iz = int(np.floor(var))\n",
    "            #print(voxel_iz)\n",
    "            \n",
    "            if voxel_ix >= self.nx:\n",
    "                voxel_ix = self.nx-1\n",
    "            if voxel_iy >= self.ny:\n",
    "                voxel_iy = self.ny-1\n",
    "            if voxel_iz>=self.nz:\n",
    "                voxel_iz = self.nz-1\n",
    "            \n",
    "            voxel_dict[voxel_ix][voxel_iy][voxel_iz]['list_of_nodes'].append(pt)\n",
    "     \n",
    "        \n",
    "        for ix in range(self.nx):\n",
    "            for iy in range(self.ny):\n",
    "                for iz in range(self.nz):\n",
    "                    for prop in self.alpha1:\n",
    "                        if prop=='number_of_points':\n",
    "                            voxel_dict[ix][iy][iz]['prop1'].append(len(voxel_dict[ix][iy][iz]['list_of_nodes']))\n",
    "                    if len(voxel_dict[ix][iy][iz]['list_of_nodes'])>0:\n",
    "                        for p, prop in enumerate(self.alpha2):\n",
    "                            if prop=='sum':\n",
    "                                voxel_dict[ix][iy][iz]['prop2'].append(np.sum(np.take(self.shortptc[self.shortptc_legend[p]],\n",
    "                                                                                 indices=voxel_dict[ix][iy][iz]['list_of_nodes'], \n",
    "                                                                                 axis=0)))\n",
    "                            elif prop=='avg':\n",
    "                                voxel_dict[ix][iy][iz]['prop2'].append(np.mean(np.take(self.shortptc[self.shortptc_legend[p]],\n",
    "                                                                                 indices=voxel_dict[ix][iy][iz]['list_of_nodes'], \n",
    "                                                                                 axis=0)))\n",
    "                            else:\n",
    "                                print('unkoen prop:', prop)\n",
    "                    else:\n",
    "                        voxel_dict[ix][iy][iz]['prop2'] = [0. for k in range(self.Nalphas)]\n",
    "                    #print('my vox', ix,iy,iz,voxel_dict[ix][iy][iz]['prop2'])\n",
    "                                 \n",
    "        return voxel_dict\n",
    "        \n",
    "    def create_voxel_matrix(self, ):\n",
    "        if self.define_alpha1_as_alpha2type:\n",
    "            voxelmatrix = np.empty((self.nx, self.ny, self.nz, self.Nalphas+len(self.alpha1)))\n",
    "            for ix in range(self.nx):\n",
    "                for iy in range(self.ny):\n",
    "                    for iz in range(self.nz):\n",
    "                        voxelmatrix[ix, iy, iz, :] = np.concatenate((self.voxel_dict[ix][iy][iz]['prop2'],\n",
    "                                                                     self.voxel_dict[ix][iy][iz]['prop1']), axis=0)\n",
    "        else:\n",
    "            voxelmatrix = np.empty((self.nx, self.ny, self.nz, self.Nalphas))\n",
    "            for ix in range(self.nx):\n",
    "                for iy in range(self.ny):\n",
    "                    for iz in range(self.nz):\n",
    "                        #print(self.voxel_dict[ix][iy][iz]['prop2'])\n",
    "                        voxelmatrix[ix, iy, iz, :] = self.voxel_dict[ix][iy][iz]['prop2']\n",
    "        return voxelmatrix\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Data and Pre-process\n",
    "df = pd.read_csv(\"Preproc/shortptc.csv\", sep=', |,', header=0, engine='python')\n",
    "df['tightness'] = df[[\"mpc\", \"rigid\", \"fastener\"]].sum(axis=1)\n",
    "\n",
    "all_tie_names = np.array([k for k in df.columns if 'tie_' in k])\n",
    "all_tie_names_float = np.array([float(k.split('_')[1]) for k in all_tie_names])\n",
    "all_ties_smaller_than_5 = np.where(all_tie_names_float<=5)[0]\n",
    "all_ties_bigger_than_5 = np.where(all_tie_names_float>5)[0]\n",
    "\n",
    "df['ties_under_5'] = df[all_tie_names[all_ties_smaller_than_5]].sum(axis=1)\n",
    "df['ties_equal_over_5'] = df[all_tie_names[all_ties_bigger_than_5]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_column_names = df.columns\n",
    "column_names_that_contain_kwd = [k for k in my_column_names if 'conn_sec' in k]\n",
    "df['connectors'] = df[column_names_that_contain_kwd].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 15)\n"
     ]
    }
   ],
   "source": [
    "shortptc = df.drop(labels=['index_x','index_y','index_z']+column_names_that_contain_kwd+[\"mpc\", \"rigid\", \"fastener\"]+list(all_tie_names), axis=1)\n",
    "print(shortptc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x', 'y', 'z', 'mass+nsm', 'bulk', 'rp02', 'bc_displacement_1_6_0.0',\n",
      "       'ic_stress_0.00023654_0.001_0.0', 'conn_load_1.0_-40100.0',\n",
      "       'conn_load_1.0_53100.0', 'conn_load_1.0_-64100.0', 'tightness',\n",
      "       'ties_under_5', 'ties_equal_over_5', 'connectors'],\n",
      "      dtype='object') 15\n"
     ]
    }
   ],
   "source": [
    "shortptc_legend = shortptc.columns\n",
    "print(shortptc_legend, len(shortptc_legend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "nx = 2\n",
    "ny = 2\n",
    "nz = 2\n",
    "alpha1 = ['number_of_points']\n",
    "alpha2 = ['avg', 'avg', 'avg', 'avg', 'avg', 'avg', 'avg', 'avg', 'sum', 'sum', 'sum', 'sum' ]\n",
    "print(len(alpha2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mins and maxs [-860.3588679999999, -528.369141, -105.15775] [-831.179387, -436.27149800000007, 125.81103999999999]\n",
      "voxel sizes 14.589740499999948 46.048821499999974 115.48439499999999\n",
      "voxel_matrix (2, 2, 2, 12)\n"
     ]
    }
   ],
   "source": [
    "train_voxel = myVoxel(nx, ny, nz, shortptc, shortptc_legend, alpha_Def1=alpha1, alpha_Def2=alpha2, define_alpha1_as_alpha2type=False).voxel_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mins and maxs [-860.3588679999999, -528.369141, -105.15775] [-831.179387, -436.27149800000007, 125.81103999999999]\n",
      "voxel sizes 14.589740499999948 46.048821499999974 115.48439499999999\n",
      "voxel_matrix (2, 2, 2, 12)\n"
     ]
    }
   ],
   "source": [
    "test_voxel = myVoxel(nx, ny, nz, shortptc, shortptc_legend, alpha_Def1=alpha1, alpha_Def2=alpha2, define_alpha1_as_alpha2type=False).voxel_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessinbg -> use only training to calcualte the mina nd amx \n",
    "# calcaulate scaling variables using training data\n",
    "new_max = 1.0\n",
    "new_min = 0.\n",
    "max_alphas = np.max(train_voxel, axis=-1) # nx xy xz \n",
    "min_alphas = np.min(train_voxel, axis=-1) # nx xy xz \n",
    "#print('max_alphas',max_alphas)\n",
    "#print('min_alphas',min_alphas)\n",
    "# preprocess all the samples \n",
    "def preprocess_voxel(train_voxel, max_alphas, min_alphas, new_max, new_min):\n",
    "    before_max_alphas = np.max(train_voxel, axis=-1) # nx xy xz \n",
    "    before_min_alphas = np.min(train_voxel, axis=-1) # nx xy xz \n",
    "    #print('before_max_alphas',before_max_alphas)\n",
    "    #print('before_min_alphas',before_min_alphas)\n",
    "    denominator = max_alphas-min_alphas # nx xy xz \n",
    "    inds = denominator>1e-10  # nx xy xz \n",
    "    tmp_max = np.reshape(max_alphas, list(inds.shape)+[1])\n",
    "    tmp_min = np.reshape(min_alphas, list(inds.shape)+[1])\n",
    "    train_voxel[inds] = ((train_voxel[inds]-tmp_min[inds])*new_max + (tmp_max[inds]-train_voxel[inds])*new_min)/(tmp_max[inds]-tmp_min[inds])\n",
    "    after_max_alphas = np.max(train_voxel, axis=-1) # nx xy xz \n",
    "    after_min_alphas = np.min(train_voxel, axis=-1) # nx xy xz \n",
    "    #print('after_max_alphas',after_max_alphas)\n",
    "    #print('after_min_alphas',after_min_alphas)\n",
    "    return train_voxel\n",
    "train_voxel = preprocess_voxel(train_voxel, max_alphas, min_alphas, new_max, new_min)\n",
    "test_voxel = preprocess_voxel(test_voxel, max_alphas, min_alphas, new_max, new_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
